{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage import data, io,filters\n",
    "\n",
    "#set train data path\n",
    "train_list_path='data/images_path/train.txt'\n",
    "train_data_path='data/images/train/%s'\n",
    "\n",
    "#load train data path\n",
    "with open(train_list_path) as f:\n",
    "    train_data_list = f.readlines()    \n",
    "#load train data&label with path\n",
    "\n",
    "\n",
    "for i,tdl in enumerate(train_data_list):\n",
    "    if i==0:\n",
    "        train_data=io.imread(train_data_path%tdl.split()[0]).reshape([-1,256*256*3])\n",
    "        train_label=np.array([int(tdl.split()[1])])\n",
    "    else:\n",
    "        tmp=io.imread(train_data_path%tdl.split()[0]).reshape([-1,256*256*3])\n",
    "        train_data=tf.concat([train_data,tmp],0)\n",
    "        \n",
    "        tmp=np.array([int(tdl.split()[1])])\n",
    "        train_label=tf.concat([train_label,tmp],0)\n",
    "\n",
    "nb_classes = 13\n",
    "numb_of_neurons=98304\n",
    "learning_rate=0.001\n",
    "#convert train_label into one hot encoding\n",
    "train_label=tf.one_hot(train_label,nb_classes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage import data, io, filters\n",
    "from mlxtend.preprocessing import one_hot\n",
    "# set train data path\n",
    "train_list_path = 'data/images_path/train.txt'\n",
    "train_data_path = 'data/images/train/%s'\n",
    "\n",
    "\n",
    "class DataRead:\n",
    "    def __init__(self, data_list_path, data_path, batch_size, nb_classes):\n",
    "        self.data_list_path = data_list_path\n",
    "        self.data_path = data_path\n",
    "        self.batch_num = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_classes = nb_classes\n",
    "\n",
    "        with open(self.data_list_path) as f:\n",
    "            self.data_list = f.readlines()\n",
    "        self.total_batch = int(np.floor(np.size(self.data_list) / self.batch_size))\n",
    "        \n",
    "        self.label_list=[int(d.split()[1]) for d in self.data_list]\n",
    "        self.data_list=[train_data_path%d.split()[0] for d in self.data_list]\n",
    "        \n",
    "    def Next_Batch(self):\n",
    "        batch_num = self.batch_num\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        data_coll=io.ImageCollection(\n",
    "            self.data_list[batch_num * batch_size:(batch_num + 1) * batch_size])\n",
    "        data=np.array([d for d in data_coll])\n",
    "        \n",
    "        label_coll=self.label_list[batch_num * batch_size:(batch_num + 1) * batch_size]\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "        \n",
    "        self.batch_num = self.batch_num + 1\n",
    "        if self.batch_num > self.total_batch:\n",
    "            self.batch_num = 0\n",
    "        return (data/255.0, label)\n",
    "    def All_Data(self):\n",
    "        data_coll=io.ImageCollection(\n",
    "            self.data_list)\n",
    "        data=np.array([d for d in data_coll])\n",
    "        \n",
    "        label_coll=self.label_list\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "        \n",
    "        return (data/255.0, label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(train_list_path) as f:\n",
    "            data_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, tdl in enumerate(data_list):\n",
    "            if batch_num * batch_size <= i < (batch_num + 1) * batch_size:\n",
    "                if first:\n",
    "                    data = io.imread(train_data_path % tdl.split()[0])\n",
    "                    first = 0\n",
    "                else:\n",
    "                    tmp = io.imread(train_data_path % tdl.split()[0])\n",
    "                    data = tf.concat([data, tmp], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=DataRead(train_list_path, train_data_path, batch_size=100, nb_classes=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c,d=a.Next_Batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(np.size(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path='data/images/train/%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=b[1:10,0]\n",
    "f='data/images/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[train_data_path%d.split()[0] for d in data_list]\n",
    "b=[int(d.split()[1]) for d in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb=b[695:711]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coll = io.ImageCollection(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=coll[:].ipynb_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g=f.concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h=np.array([i for i in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0:666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=one_hot(bb,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage import data, io, filters\n",
    "from mlxtend.preprocessing import one_hot\n",
    "import random\n",
    "\n",
    "# set train data path\n",
    "train_list_path = 'data/images_path/train.txt'\n",
    "train_data_path = 'data/images/train/%s'\n",
    "\n",
    "\n",
    "class DataRead:\n",
    "    def __init__(self, data_list_path, data_path, batch_size, nb_classes):\n",
    "        self.data_list_path = data_list_path\n",
    "        self.data_path = data_path\n",
    "        self.batch_num = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_classes = nb_classes\n",
    "\n",
    "        with open(self.data_list_path) as f:\n",
    "            self.data_list = f.readlines()\n",
    "        self.total_batch = int(np.floor(np.size(self.data_list) / self.batch_size))\n",
    "\n",
    "        self.label_list = [int(d.split()[1]) for d in self.data_list]\n",
    "        self.data_list = [train_data_path % d.split()[0] for d in self.data_list]\n",
    "\n",
    "        # shuffle data\n",
    "        ind_shuff = np.arange(np.size(self.data_list))\n",
    "        random.shuffle(ind_shuff)\n",
    "        self.data_list = [self.data_list[i] for i in ind_shuff]\n",
    "        self.label_list = [self.label_list[i] for i in ind_shuff]\n",
    "\n",
    "        ind_tmp = int(np.size(self.data_list) / 10/)\n",
    "        self.label_list = self.label_list[ind_tmp:]\n",
    "        self.data_list = self.data_list[ind_tmp:]\n",
    "\n",
    "        self.test_label_list = self.label_list[:ind_tmp]\n",
    "        self.test_data_list = self.data_list[:ind_tmp]\n",
    "\n",
    "    def Next_Batch(self):\n",
    "        batch_num = int(self.batch_num)\n",
    "        batch_size = int(self.batch_size)\n",
    "\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.data_list[batch_num * batch_size:(batch_num + 1) * batch_size])\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.label_list[batch_num * batch_size:(batch_num + 1) * batch_size]\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "\n",
    "        self.batch_num = self.batch_num + 1\n",
    "        if self.batch_num > self.total_batch:\n",
    "            self.batch_num = 0\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "    def All_Data(self):\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.data_list)\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.label_list\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "    def Test_Data(self):\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.test_data_list)\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.test_label_list\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "\n",
    "nb_classes = 13\n",
    "learning_rate = 0.001\n",
    "training_epochs = 45\n",
    "batch_size = 256\n",
    "train = DataRead(train_list_path, train_data_path, batch_size=batch_size, nb_classes=13)\n",
    "test_x,text_y=train.Test_Data()\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "X_img = X\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([11, 11, 3, 96], stddev=0.001))\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 96, 256], stddev=0.001))\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 256, 384], stddev=0.001))\n",
    "W4 = tf.Variable(tf.random_normal([3, 3, 384, 384], stddev=0.001))\n",
    "W5 = tf.Variable(tf.random_normal([3, 3, 384, 256], stddev=0.001))\n",
    "W6 = tf.get_variable(\"W6\", shape=[8 * 8 * 256, 4096], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random_normal([4096]))\n",
    "W7 = tf.get_variable(\"W7\", shape=[4096, 1000], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random_normal([1000]))\n",
    "W8 = tf.get_variable(\"W8\", shape=[1000, 100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b8 = tf.Variable(tf.random_normal([100]))\n",
    "W9 = tf.get_variable(\"W9\", shape=[100, nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b9 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 4, 4, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer4\") as scope:\n",
    "    L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L4 = tf.nn.relu(L4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer5\") as scope:\n",
    "    L5 = tf.nn.conv2d(L4, W5, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L5 = tf.nn.relu(L5)\n",
    "    L5 = tf.nn.max_pool(L5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L5 = tf.reshape(L5, [-1, 8 * 8 * 256])\n",
    "    L5 = tf.nn.dropout(L5, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer6\") as scope:\n",
    "    L6 = tf.nn.relu(tf.matmul(L5, W6) + b6)\n",
    "    L6 = tf.nn.dropout(L6, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer7\") as scope:\n",
    "    L7 = tf.nn.relu(tf.matmul(L6, W7) + b7)\n",
    "    L7 = tf.nn.dropout(L7, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer8\") as scope:\n",
    "    L8 = tf.nn.relu(tf.matmul(L7, W8) + b8)\n",
    "    L8 = tf.nn.dropout(L8, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer9\") as scope:\n",
    "    logits = tf.matmul(L8, W9) + b9\n",
    "\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"prediction\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# train my model\n",
    "with tf.Session() as sess:\n",
    "    print('Learning started. It takes sometime.')\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./logs/KIST/learning_rate_0_001')\n",
    "    writer.add_graph(sess.graph)\n",
    "    step = 0\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        avg_a = 0\n",
    "        total_batch = train.total_batch\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = train.Next_Batch()\n",
    "            feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "            c, _,s = sess.run([cost, optimizer,merged_summary], feed_dict=feed_dict)\n",
    "            a=sess.run(accuracy, feed_dict={X:test_x, Y:text_y, keep_prob: 1})\n",
    "            avg_cost += c / total_batch\n",
    "            avg_a += a / total_batch\n",
    "\n",
    "            writer.add_summary(s, global_step=step)\n",
    "            step += 1\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'accuracy =', '{:.9f}'.format(avg_a))\n",
    "\n",
    "    val_list_path = 'data/images_path/val.txt'\n",
    "    val_data_path = 'data/images/val/%s'\n",
    "    val = DataRead(val_list_path, val_data_path, batch_size=100, nb_classes=13)\n",
    "\n",
    "    val_x, val_y = val.Next_Batch()\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={X: val_x, Y: val_y, keep_prob: 1}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 2.866823452 accuracy = 0.208043981\n",
      "Epoch: 0002 cost = 1.823801659 accuracy = 0.423141439\n",
      "Epoch: 0003 cost = 1.502379576 accuracy = 0.477078301\n",
      "Epoch: 0004 cost = 1.464128318 accuracy = 0.481707931\n",
      "Epoch: 0005 cost = 1.335007120 accuracy = 0.505290106\n",
      "Epoch: 0006 cost = 1.350503370 accuracy = 0.503637866\n",
      "Epoch: 0007 cost = 1.324790760 accuracy = 0.503759477\n",
      "Epoch: 0008 cost = 1.238530879 accuracy = 0.520583819\n",
      "Epoch: 0009 cost = 1.120865062 accuracy = 0.573843431\n",
      "Epoch: 0010 cost = 1.013975106 accuracy = 0.606582125\n",
      "Epoch: 0011 cost = 0.860219377 accuracy = 0.666991662\n",
      "Epoch: 0012 cost = 0.799016599 accuracy = 0.689397560\n",
      "Epoch: 0013 cost = 0.709085873 accuracy = 0.733370657\n",
      "Epoch: 0014 cost = 0.645612955 accuracy = 0.766295961\n",
      "Epoch: 0015 cost = 0.608599535 accuracy = 0.782560472\n",
      "Epoch: 0016 cost = 0.552817200 accuracy = 0.802049787\n",
      "Epoch: 0017 cost = 0.520392292 accuracy = 0.821581037\n",
      "Epoch: 0018 cost = 0.537029433 accuracy = 0.816041417\n",
      "Epoch: 0019 cost = 0.450476760 accuracy = 0.849358815\n",
      "Epoch: 0020 cost = 0.410336826 accuracy = 0.862524324\n",
      "Epoch: 0021 cost = 0.414240174 accuracy = 0.863906083\n",
      "Epoch: 0022 cost = 0.371875254 accuracy = 0.877589491\n",
      "Epoch: 0023 cost = 0.351130493 accuracy = 0.885318120\n",
      "Epoch: 0024 cost = 0.329535748 accuracy = 0.892323370\n",
      "Epoch: 0025 cost = 0.316560008 accuracy = 0.894843667\n",
      "Epoch: 0026 cost = 0.298685742 accuracy = 0.903710833\n",
      "Epoch: 0027 cost = 0.262858529 accuracy = 0.916152963\n",
      "Epoch: 0028 cost = 0.222867810 accuracy = 0.928077194\n",
      "Epoch: 0029 cost = 0.232607855 accuracy = 0.924189815\n",
      "Epoch: 0030 cost = 0.227085162 accuracy = 0.927087528\n",
      "Epoch: 0031 cost = 0.188845966 accuracy = 0.937481130\n",
      "Epoch: 0032 cost = 0.198996485 accuracy = 0.937915157\n",
      "Epoch: 0033 cost = 0.192717294 accuracy = 0.941429315\n",
      "Epoch: 0034 cost = 0.180911429 accuracy = 0.940869481\n",
      "Epoch: 0035 cost = 0.187202060 accuracy = 0.940127231\n",
      "Epoch: 0036 cost = 0.176776991 accuracy = 0.943846870\n",
      "Epoch: 0037 cost = 0.187900431 accuracy = 0.938867083\n",
      "Epoch: 0038 cost = 0.154434649 accuracy = 0.950585833\n",
      "Epoch: 0039 cost = 0.136661444 accuracy = 0.955999648\n",
      "Epoch: 0040 cost = 0.121110783 accuracy = 0.961847491\n",
      "Epoch: 0041 cost = 0.149380454 accuracy = 0.951864852\n",
      "Epoch: 0042 cost = 0.143554724 accuracy = 0.955131593\n",
      "Epoch: 0043 cost = 0.122574037 accuracy = 0.961455398\n",
      "Epoch: 0044 cost = 0.127862473 accuracy = 0.959243324\n",
      "Epoch: 0045 cost = 0.113679058 accuracy = 0.960937500\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage import data, io, filters\n",
    "from mlxtend.preprocessing import one_hot\n",
    "import random\n",
    "\n",
    "# set train data path\n",
    "train_list_path = 'data/images_path/train.txt'\n",
    "train_data_path = 'data/images/train/%s'\n",
    "\n",
    "\n",
    "class DataRead:\n",
    "    def __init__(self, data_list_path, data_path, batch_size, nb_classes):\n",
    "        self.data_list_path = data_list_path\n",
    "        self.data_path = data_path\n",
    "        self.batch_num = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_classes = nb_classes\n",
    "\n",
    "        with open(self.data_list_path) as f:\n",
    "            self.data_list = f.readlines()\n",
    "        self.total_batch = int(np.floor(np.size(self.data_list) / self.batch_size))\n",
    "\n",
    "        self.label_list = [int(d.split()[1]) for d in self.data_list]\n",
    "        self.data_list = [train_data_path % d.split()[0] for d in self.data_list]\n",
    "\n",
    "        # shuffle data\n",
    "        ind_shuff = np.arange(np.size(self.data_list))\n",
    "        random.shuffle(ind_shuff)\n",
    "        self.data_list = [self.data_list[i] for i in ind_shuff]\n",
    "        self.label_list = [self.label_list[i] for i in ind_shuff]\n",
    "\n",
    "    def Next_Batch(self):\n",
    "        batch_num = int(self.batch_num)\n",
    "        batch_size = int(self.batch_size)\n",
    "\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.data_list[batch_num * batch_size:(batch_num + 1) * batch_size])\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.label_list[batch_num * batch_size:(batch_num + 1) * batch_size]\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "\n",
    "        self.batch_num = self.batch_num + 1\n",
    "        if self.batch_num > self.total_batch:\n",
    "            self.batch_num = 0\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "    def Next_batch_not_one_hot(self):\n",
    "        batch_num = int(self.batch_num)\n",
    "        batch_size = int(self.batch_size)\n",
    "\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.data_list[batch_num * batch_size:(batch_num + 1) * batch_size])\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.label_list[batch_num * batch_size:(batch_num + 1) * batch_size]\n",
    "        label = label_coll\n",
    "\n",
    "        self.batch_num = self.batch_num + 1\n",
    "        if self.batch_num > self.total_batch:\n",
    "            self.batch_num = 0\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "    def All_Data(self):\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.data_list)\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.label_list\n",
    "        label = one_hot(label_coll, self.nb_classes)\n",
    "\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "    def All_Data_not_one_hot(self):\n",
    "        data_coll = io.ImageCollection(\n",
    "            self.data_list)\n",
    "        data = np.array([d for d in data_coll])\n",
    "\n",
    "        label_coll = self.label_list\n",
    "        label = label_coll\n",
    "\n",
    "        return (data / 255.0, label)\n",
    "\n",
    "nb_classes = 13\n",
    "learning_rate = 0.001\n",
    "training_epochs = 45\n",
    "batch_size = 256\n",
    "train = DataRead(train_list_path, train_data_path, batch_size=batch_size, nb_classes=13)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "X_img = X\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([11, 11, 3, 96], stddev=0.001))\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 96, 256], stddev=0.001))\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 256, 384], stddev=0.001))\n",
    "W4 = tf.Variable(tf.random_normal([3, 3, 384, 384], stddev=0.001))\n",
    "W5 = tf.Variable(tf.random_normal([3, 3, 384, 256], stddev=0.001))\n",
    "W6 = tf.get_variable(\"W6\", shape=[8 * 8 * 256, 4096], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random_normal([4096]))\n",
    "W7 = tf.get_variable(\"W7\", shape=[4096, 1000], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random_normal([1000]))\n",
    "W8 = tf.get_variable(\"W8\", shape=[1000, 100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b8 = tf.Variable(tf.random_normal([100]))\n",
    "W9 = tf.get_variable(\"W9\", shape=[100, nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b9 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 4, 4, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer4\") as scope:\n",
    "    L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L4 = tf.nn.relu(L4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer5\") as scope:\n",
    "    L5 = tf.nn.conv2d(L4, W5, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L5 = tf.nn.relu(L5)\n",
    "    L5 = tf.nn.max_pool(L5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L5 = tf.reshape(L5, [-1, 8 * 8 * 256])\n",
    "    L5 = tf.nn.dropout(L5, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer6\") as scope:\n",
    "    L6 = tf.nn.relu(tf.matmul(L5, W6) + b6)\n",
    "    L6 = tf.nn.dropout(L6, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer7\") as scope:\n",
    "    L7 = tf.nn.relu(tf.matmul(L6, W7) + b7)\n",
    "    L7 = tf.nn.dropout(L7, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer8\") as scope:\n",
    "    L8 = tf.nn.relu(tf.matmul(L7, W8) + b8)\n",
    "    L8 = tf.nn.dropout(L8, keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"layer9\") as scope:\n",
    "    logits = tf.matmul(L8, W9) + b9\n",
    "\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"prediction\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# train my model\n",
    "sess=tf.Session()\n",
    "print('Learning started. It takes sometime.')\n",
    "merged_summary = tf.summary.merge_all()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter('./logs/KIST/learning_rate_0_001')\n",
    "writer.add_graph(sess.graph)\n",
    "step = 0\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    avg_a = 0\n",
    "    total_batch = train.total_batch\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = train.Next_Batch()\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _, a,s = sess.run([cost, optimizer, accuracy,merged_summary], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_a += a / total_batch\n",
    "\n",
    "        writer.add_summary(s, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'accuracy =', '{:.9f}'.format(avg_a))\n",
    "\n",
    "score_rcv=[]\n",
    "score_sv=[]\n",
    "score_dt=[]\n",
    "score_cnn=[]\n",
    "\n",
    "val_list_path = 'data/images_path/val.txt'\n",
    "val_data_path = 'data/images/val/%s'\n",
    "val = DataRead(val_list_path, val_data_path, batch_size=128, nb_classes=13)\n",
    "total_batch_test=val.total_batch\n",
    "\n",
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "clf_dt=tree.DecisionTreeClassifier(criterion='entropy',max_depth=None)\n",
    "\n",
    "#RidgeClassifier\n",
    "from sklearn.linear_model import LinearRegression, RidgeClassifierCV\n",
    "rcv=RidgeClassifierCV()\n",
    "\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "clf_sv=svm.SVC(kernel='linear',C=1)\n",
    "\n",
    "#test data set for others (except CNN)\n",
    "text_x,text_y=val.All_Data_not_one_hot()\n",
    "text_x=np.array([d.reshape([3*256*256]) for d in text_x])\n",
    "\n",
    "for i in range(total_batch_test):\n",
    "    val_x, val_y = val.Next_Batch()\n",
    "    #AlexNet\n",
    "    a=sess.run(accuracy, feed_dict={X: val_x, Y: val_y, keep_prob: 1})\n",
    "    score_cnn=np.append(score_cnn,a)\n",
    "    \n",
    "    x,y=train.Next_batch_not_one_hot()\n",
    "    x=np.array([d.reshape([3*256*256]) for d in x])\n",
    "    \n",
    "    #Decision Tree\n",
    "    clf_dt.fit(x,y)\n",
    "    score_dt=np.append(score_dt,clf_dt.score(text_x,text_y))\n",
    "    \n",
    "    #RidgeClassifier\n",
    "    rcv.fit(x,y)\n",
    "    score_rcv=np.append(score_rcv,rcv.score(text_x,text_y))\n",
    "    \n",
    "    #support_vector machine\n",
    "    clf_sv.fit(x,y)\n",
    "    score_sv=np.append(score_sv,clf_sv.score(text_x,text_y))\n",
    "\n",
    "print('Accuracy of Decision Tree : ',score_dt.mean())\n",
    "print('Accuracy of LinearRCV : ',score_rcv.mean())\n",
    "print('Accuracy of SVM : ',score_sv.mean())\n",
    "print('Accuracy of CNN : ',score_cnn.mean())\n",
    "\n",
    "value=(score_rcv.mean(),score_sv.mean(),score_dt.mean(),score_cnn.mean())\n",
    "std=(score_rcv.std(),score_sv.std(),score_dt.std(),score_cnn.std())\n",
    "classifiers = ('LinearRCV', 'SVM', 'DT', 'AlexNet')\n",
    "y_pos = np.arange(len(classifiers))\n",
    "\n",
    "plt.bar(y_pos, value, yerr=std, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, classifiers)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance of The Different Classifiers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-4d579fd8ca31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtext_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAll_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtext_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e9e16cfd75d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAll_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x,y=train.Next_Batch()\n",
    "x=np.array([d.reshape([3*256*256]) for d in x])\n",
    "\n",
    "clf_dt=tree.DecisionTreeClassifier(criterion='entropy',max_depth=None)\n",
    "clf_dt.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-186ac6806f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#support_vector machine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mclf_sv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mscore_sv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_sv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_sv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of Decision Tree : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score_rcv=[]\n",
    "score_sv=[]\n",
    "score_dt=[]\n",
    "score_cnn=[]\n",
    "\n",
    "val_list_path = 'data/images_path/val.txt'\n",
    "val_data_path = 'data/images/val/%s'\n",
    "val = DataRead(val_list_path, val_data_path, batch_size=128, nb_classes=13)\n",
    "total_batch_test=val.total_batch\n",
    "\n",
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "clf_dt=tree.DecisionTreeClassifier(criterion='entropy',max_depth=None)\n",
    "\n",
    "#RidgeClassifier\n",
    "from sklearn.linear_model import LinearRegression, RidgeClassifierCV\n",
    "rcv=RidgeClassifierCV()\n",
    "\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "clf_sv=svm.SVC(kernel='linear',C=1)\n",
    "\n",
    "#test data set for others (except CNN)\n",
    "text_x,text_y=val.All_Data_not_one_hot()\n",
    "text_x=np.array([d.reshape([3*256*256]) for d in text_x])\n",
    "\n",
    "for i in range(total_batch_test):\n",
    "    val_x, val_y = val.Next_Batch()\n",
    "    #AlexNet\n",
    "    a=sess.run(accuracy, feed_dict={X: val_x, Y: val_y, keep_prob: 1})\n",
    "    score_cnn=np.append(score_cnn,a)\n",
    "    \n",
    "    x,y=train.Next_batch_not_one_hot()\n",
    "    x=np.array([d.reshape([3*256*256]) for d in x])\n",
    "    \n",
    "    #Decision Tree\n",
    "    clf_dt.fit(x,y)\n",
    "    score_dt=np.append(score_dt,clf_dt.score(text_x,text_y))\n",
    "    \n",
    "    #RidgeClassifier\n",
    "    rcv.fit(x,y)\n",
    "    score_rcv=np.append(score_rcv,rcv.score(text_x,text_y))\n",
    "    \n",
    "    #support_vector machine\n",
    "    clf_sv.fit(x,y)\n",
    "    score_sv=np.append(score_sv,clf_sv.score(text_x,text_y))\n",
    "\n",
    "print('Accuracy of Decision Tree : ',score_dt.mean())\n",
    "print('Accuracy of LinearRCV : ',score_rcv.mean())\n",
    "print('Accuracy of SVM : ',score_sv.mean())\n",
    "print('Accuracy of CNN : ',score_cnn.mean())\n",
    "\n",
    "value=(score_rcv.mean(),score_sv.mean(),score_dt.mean(),score_cnn.mean())\n",
    "std=(score_rcv.std(),score_sv.std(),score_dt.std(),score_cnn.std())\n",
    "classifiers = ('LinearRCV', 'SVM', 'DT', 'AlexNet')\n",
    "y_pos = np.arange(len(classifiers))\n",
    "\n",
    "plt.bar(y_pos, value, yerr=std, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, classifiers)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance of The Different Classifiers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5581638   0.55242567]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in range(total_batch_test):\n",
    "#     print(i)\n",
    "\n",
    "print(score_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61398018  0.64840897]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in range(total_batch_test):\n",
    "#     print(i)\n",
    "x,y=train.Next_batch_not_one_hot()\n",
    "x=np.array([d.reshape([3*256*256]) for d in x])\n",
    "\n",
    "print(score_rcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x,y=train.Next_batch_not_one_hot()\n",
    "x=np.array([d.reshape([3*256*256]) for d in x])\n",
    "\n",
    "print(score_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72822118  0.6875326 ]\n"
     ]
    }
   ],
   "source": [
    "print(score_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f676402d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP8fG5AewyJCTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6766f53710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value=(score_rcv.mean(),score_sv.mean(),score_dt.mean(),score_cnn.mean())\n",
    "std=(score_rcv.std(),score_sv.std(),score_dt.std(),score_cnn.std())\n",
    "classifiers = ('LinearRCV', 'SVM', 'DT', 'AlexNet')\n",
    "y_pos = np.arange(len(classifiers))\n",
    "\n",
    "plt.bar(y_pos, value, yerr=std, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, classifiers)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance of The Different Classifiers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
