{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight=tf.constant([[[[1.]],[[1.]]],\n",
    "                    [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d=tf.nn.conv2d(image,weight,strides=[1,1,1,1],padding='VALID')\n",
    "#hmm why does it set strides to 1 1 1 1 ??? what does it mean?\n",
    "conv2d_img=conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "\n",
    "#this is show what is result.\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image.shape\",image.shape)\n",
    "weight=tf.constant([[[[1.0,  10.0, -1.0]],[[1.0,  10.0, -1.0]]],\n",
    "                    [[[1.0,  10.0, -1.0]],[[1.0,  10.0, -1.0]]]])\n",
    "print(\"weight.shape\",weight.shape)\n",
    "conv2d= tf.nn.conv2d(image, weight, strides=[1,1,1,1],padding='SAME')\n",
    "conv2d_img=conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgae=np.array([[[[4],[3]],\n",
    "                [[2],[1]]]],dtype=np.float32)\n",
    "pool=tf.nn.max_pool(image, ksize=[1, 2, 2, 1], \n",
    "                   strides=[1,1,1,1],padding='VALID')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "img=img.reshape(-1,28,28,1)\n",
    "W1=tf.Variable(tf.random_normal([3,3,1,5],stddev=0.01))\n",
    "conv2d=tf.nn.conv2d(img,W1,strides=[1,2,2,1], padding='SAME')\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME')\n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None, 784])\n",
    "X_img=tf.reshape(X,[-1,28,28,1])\n",
    "Y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([3,3,1,32],stddev=0.001))\n",
    "L1=tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')\n",
    "L1=tf.nn.relu(L1)\n",
    "L1=tf.nn.max_pool(L1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([3,3,32,64],stddev=0.001))\n",
    "L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "L2=tf.nn.relu(L2)\n",
    "L2=tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L2=tf.reshape(L2,[-1,7*7*64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits=tf.matmul(L2,W3)+b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None, 784])\n",
    "X_img=tf.reshape(X,[-1,28,28,1])\n",
    "Y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([3,3,1,32],stddev=0.001))\n",
    "L1=tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')\n",
    "L1=tf.nn.relu(L1)\n",
    "L1=tf.nn.max_pool(L1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L1=tf.nn.dropout(L1,keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([3,3,32,64],stddev=0.001))\n",
    "L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "L2=tf.nn.relu(L2)\n",
    "L2=tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L2=tf.nn.dropout(L2,keep_prob=keep_prob)\n",
    "\n",
    "W3=tf.Variable(tf.random_normal([3,3,64,128],stddev=0.001))\n",
    "L3=tf.nn.conv2d(L2,W3,strides=[1,1,1,1],padding='SAME')\n",
    "L3=tf.nn.relu(L3)\n",
    "L3=tf.nn.max_pool(L3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L3=tf.reshape(L3,[-1,4*4*128])\n",
    "L3=tf.nn.dropout(L3,keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[4 * 4 * 128, 625],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4=tf.nn.relu(tf.matmul(L3,W4)+b4)\n",
    "L4=tf.nn.dropout(L4,keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits=tf.matmul(L4,W5)+b5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys,keep_prob:0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels,keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=mnist.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=mnist.train.labels[mnist.train.labels<=1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=mnist.train.images[mnist.train.labels<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.append(data,label,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage import data, io, filters\n",
    "from mlxtend.preprocessing import one_hot\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# set train data path\n",
    "train_data_path = 'data/out.txt'\n",
    "class DataRead:\n",
    "    def __init__(self, data_path,batch_size,prepro=True,pro_data=0):\n",
    "        self.data_path=data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_num = 0\n",
    "        \n",
    "        #data read & preprocessing\n",
    "        if(prepro):\n",
    "            #data read\n",
    "            with open(train_data_path) as f:\n",
    "                data=f.readlines()\n",
    "                \n",
    "            #data preprocessing\n",
    "            a=np.arange(np.size(data))\n",
    "            a=a[a%2!=0]\n",
    "            tmp=[data[i] for i in a]\n",
    "            train_string=[d.split(\",\")[:] for d in tmp]\n",
    "            for i in range(np.size(train_string,0)):\n",
    "                train_string[i][-1]=float(train_string[i][-1]=='t\\n')\n",
    "            train=np.array([[float(d) for d in line ]for line in train_string])\n",
    "        else:\n",
    "            train=pro_data\n",
    "        \n",
    "        #total_batch\n",
    "        self.total_batch = int(np.floor(np.size(train,0) / self.batch_size))\n",
    "        \n",
    "        # shuffle\n",
    "        ind_shuff=np.arange(np.size(train,0))\n",
    "        random.shuffle(ind_shuff)\n",
    "        train=train[ind_shuff,:]\n",
    "        \n",
    "        self.train=train[:,:-1]\n",
    "        self.label=train[:,-1].reshape(-1,1)\n",
    "        \n",
    "    def Next_Batch(self):\n",
    "        batch_num = int(self.batch_num)\n",
    "        batch_size = int(self.batch_size)\n",
    "        \n",
    "        data=self.train[batch_num * batch_size:(batch_num + 1) * batch_size,:]\n",
    "        label=self.label[batch_num * batch_size:(batch_num + 1) * batch_size]\n",
    "        \n",
    "        self.batch_num = self.batch_num + 1\n",
    "        if self.batch_num > self.total_batch:\n",
    "            self.batch_num = 0\n",
    "        return (data , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=DataRead(train_data_path,40,False,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 1\n",
    "learning_rate = 0.001\n",
    "training_epochs = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None, 784])\n",
    "X_img=tf.reshape(X,[-1,28,28,1])\n",
    "Y=tf.placeholder(tf.float32,[None,nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W1=tf.Variable(tf.random_normal([3,3,1,32],stddev=0.001))\n",
    "L1=tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')\n",
    "L1=tf.nn.relu(L1)\n",
    "L1=tf.nn.max_pool(L1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L1=tf.nn.dropout(L1,keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([3,3,32,64],stddev=0.001))\n",
    "L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "L2=tf.nn.relu(L2)\n",
    "L2=tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L2=tf.nn.dropout(L2,keep_prob=keep_prob)\n",
    "\n",
    "W3=tf.Variable(tf.random_normal([3,3,64,128],stddev=0.001))\n",
    "L3=tf.nn.conv2d(L2,W3,strides=[1,1,1,1],padding='SAME')\n",
    "L3=tf.nn.relu(L3)\n",
    "L3=tf.nn.max_pool(L3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "L3=tf.reshape(L3,[-1,4*4*128])\n",
    "L3=tf.nn.dropout(L3,keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[4 * 4 * 128, 625],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4=tf.nn.relu(tf.matmul(L3,W4)+b4)\n",
    "L4=tf.nn.dropout(L4,keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([1]))\n",
    "logits=tf.matmul(L4,W5)+b5\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch =  train.total_batch\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = train.Next_Batch()\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys,keep_prob:0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(label[label==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class park:\n",
    "    def __init__(self,k,d):\n",
    "    self.k=k\n",
    "    self.d=d\n",
    "    \n",
    "class family(park):\n",
    "    par\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.misc\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from math import ceil\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "img1 = scp.misc.imread(\"../Semantic_segmentation/FCN/tensorflow-fcn-master/test_data/tabby_cat.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-183-c5b27a687a80>, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-183-c5b27a687a80>\"\u001b[0;36m, line \u001b[0;32m132\u001b[0m\n\u001b[0;31m    value = (1 - abs(x / f - c)) * (1 - abs(y / f - c)) ( 1 - |  |)\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from math import ceil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "images = tf.placeholder(\"float\")\n",
    "feed_dict = {images: img1}\n",
    "batch_images = tf.expand_dims(images, 0)\n",
    "X=batch_images\n",
    "\n",
    "W1_1=tf.Variable(tf.random_normal([3,3,3,64],stddev=0.001))\n",
    "L1_1=tf.nn.conv2d(X,W1_1,strides=[1,1,1,1],padding='SAME')\n",
    "b1_1 = tf.Variable(tf.random_normal([64]))\n",
    "L1_1 = tf.nn.bias_add(L1_1, b1_1)\n",
    "L1_1=tf.nn.relu(L1_1)\n",
    "\n",
    "W1_2=tf.Variable(tf.random_normal([3,3,64,64],stddev=0.001))\n",
    "L1_2=tf.nn.conv2d(L1_1,W1_2,strides=[1,1,1,1],padding='SAME')\n",
    "b1_2 = tf.Variable(tf.random_normal([64]))\n",
    "L1_2 = tf.nn.bias_add(L1_2, b1_2)\n",
    "L1_2=tf.nn.relu(L1_2)# (?, 368, 489, 64)\n",
    "L1=tf.nn.max_pool(L1_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') #(?, 185, 245, 64)\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "W2_1=tf.Variable(tf.random_normal([3,3,64,128],stddev=0.001))\n",
    "L2_1=tf.nn.conv2d(L1,W2_1,strides=[1,1,1,1],padding='SAME')\n",
    "b2_1 = tf.Variable(tf.random_normal([128]))\n",
    "L2_1 = tf.nn.bias_add(L2_1, b2_1)\n",
    "L2_1=tf.nn.relu(L2_1)\n",
    "\n",
    "W2_2=tf.Variable(tf.random_normal([3,3,128,128],stddev=0.001))\n",
    "L2_2=tf.nn.conv2d(L2_1,W2_2,strides=[1,1,1,1],padding='SAME')\n",
    "b2_2 = tf.Variable(tf.random_normal([128]))\n",
    "L2_2 = tf.nn.bias_add(L2_2, b2_2)\n",
    "L2_2=tf.nn.relu(L2_2)# (?, 185, 245, 128)\n",
    "L2=tf.nn.max_pool(L2_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') #(?, 92, 123, 128)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "W3_1=tf.Variable(tf.random_normal([3,3,128,256],stddev=0.001))\n",
    "L3_1=tf.nn.conv2d(L2,W3_1,strides=[1,1,1,1],padding='SAME')\n",
    "b3_1 = tf.Variable(tf.random_normal([256]))\n",
    "L3_1 = tf.nn.bias_add(L3_1, b3_1)\n",
    "L3_1=tf.nn.relu(L3_1)\n",
    "\n",
    "W3_2=tf.Variable(tf.random_normal([3,3,256,256],stddev=0.001))\n",
    "L3_2=tf.nn.conv2d(L3_1,W3_2,strides=[1,1,1,1],padding='SAME')\n",
    "b3_2 = tf.Variable(tf.random_normal([256]))\n",
    "L3_2 = tf.nn.bias_add(L3_2, b3_2)\n",
    "L3_2=tf.nn.relu(L3_2)# (?, 92, 123, 256)\n",
    "L3=tf.nn.max_pool(L3_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') #(?, 46, 62, 256)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "W4_1=tf.Variable(tf.random_normal([3,3,256,512],stddev=0.001))\n",
    "L4_1=tf.nn.conv2d(L3,W4_1,strides=[1,1,1,1],padding='SAME')\n",
    "b4_1 = tf.Variable(tf.random_normal([512]))\n",
    "L4_1 = tf.nn.bias_add(L4_1, b4_1)\n",
    "L4_1=tf.nn.relu(L4_1)\n",
    "\n",
    "W4_2=tf.Variable(tf.random_normal([3,3,512,512],stddev=0.001))\n",
    "L4_2=tf.nn.conv2d(L4_1,W4_2,strides=[1,1,1,1],padding='SAME')\n",
    "b4_2 = tf.Variable(tf.random_normal([512]))\n",
    "L4_2 = tf.nn.bias_add(L4_2, b4_2)\n",
    "L4_2=tf.nn.relu(L4_2)# (?, 46, 62, 512)\n",
    "L4=tf.nn.max_pool(L4_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') #(?, 23, 31, 512)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "W5_1=tf.Variable(tf.random_normal([3,3,512,512],stddev=0.001))\n",
    "L5_1=tf.nn.conv2d(L4,W5_1,strides=[1,1,1,1],padding='SAME')\n",
    "b5_1 = tf.Variable(tf.random_normal([512]))\n",
    "L5_1 = tf.nn.bias_add(L5_1, b5_1)\n",
    "L5_1=tf.nn.relu(L5_1)\n",
    "\n",
    "W5_2=tf.Variable(tf.random_normal([3,3,512,512],stddev=0.001))\n",
    "L5_2=tf.nn.conv2d(L5_1,W5_2,strides=[1,1,1,1],padding='SAME')\n",
    "b5_2 = tf.Variable(tf.random_normal([512]))\n",
    "L5_2 = tf.nn.bias_add(L5_2, b5_2)\n",
    "L5_2=tf.nn.relu(L5_2)# (?, 23, 31, 512)\n",
    "L5=tf.nn.max_pool(L5_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') #(?, 12, 16, 512)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "filt_fc6=tf.Variable(tf.random_normal([7,7,512,4096],stddev=0.001))\n",
    "fc6=tf.nn.conv2d(L5,filt_fc6,strides=[1,1,1,1],padding='SAME')\n",
    "fc6_b = tf.Variable(tf.random_normal([4096]))\n",
    "fc6 = tf.nn.bias_add(fc6, fc6_b)\n",
    "fc6 = tf.nn.relu(fc6)#(?, 12, 16, 4096)\n",
    "#fc6 = tf.nn.dropout(fc6, 0.5) for train\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "filt_fc7=tf.Variable(tf.random_normal([1,1,4096,4096],stddev=0.001))\n",
    "fc7=tf.nn.conv2d(fc6,filt_fc7,strides=[1,1,1,1],padding='SAME')\n",
    "fc7_b = tf.Variable(tf.random_normal([4096]))\n",
    "fc7 = tf.nn.bias_add(fc7, fc7_b)\n",
    "fc7 = tf.nn.relu(fc7)#(?, 12, 16, 4096)\n",
    "#fc7= tf.nn.dropout(fc6, 0.5) for train\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "filt_fc8=tf.Variable(tf.random_normal([1,1,4096,1000],stddev=0.001))\n",
    "fc8=tf.nn.conv2d(fc7,filt_fc8,strides=[1,1,1,1],padding='SAME')\n",
    "fc8_b = tf.Variable(tf.random_normal([1000]))\n",
    "fc8 = tf.nn.bias_add(fc8, fc8_b) #(?, 12, 16, 1000)\n",
    "#fc8 = tf.nn.relu(fc8)\n",
    "#fc8= tf.nn.dropout(fc6, 0.5) for train\n",
    "\n",
    "pred = tf.argmax(fc8, dimension=3)\n",
    "\n",
    "\n",
    "bottom=fc8 # ?,12,16,1000\n",
    "shape=tf.shape(L4) # ? , 23 , 31, 512\n",
    "stride=2\n",
    "ksize=4\n",
    "num_classes=1000\n",
    "strides = [1, stride, stride, 1] # = [1 , 2, 2, 1]\n",
    "in_features = bottom.get_shape()[3].value # = 1000\n",
    "new_shape = [shape[0], shape[1], shape[2], num_classes] # ?, 23, 31, 1000\n",
    "output_shape = tf.stack(new_shape)\n",
    "\n",
    "f_shape = [ksize, ksize, num_classes, in_features] # 4,4,1000,1000\n",
    "\n",
    "num_input = ksize * ksize * in_features / stride\n",
    "stddev = (2 / num_input)**0.5\n",
    "\n",
    "width = f_shape[0] # 4\n",
    "height = f_shape[1] # 4\n",
    "f = ceil(width/2.0) # 4 / 2 = 2\n",
    "c = (2 * f - 1 - f % 2) / (2.0 * f) # 2*2-1 -2%2 /(2*2)= (4-1-1)/4=0.5\n",
    "bilinear = np.zeros([f_shape[0], f_shape[1]]) # 4x4 zero matrix\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        value = (1 - abs(x / f - c)) * (1 - abs(y / f - c)) # ( 1 - | x /2 -0.5 ) * (1 - | y/2 - 0.5)\n",
    "        bilinear[x, y] = value\n",
    "weights = np.zeros(f_shape)\n",
    "for i in range(f_shape[2]):\n",
    "    weights[:, :, i, i] = bilinear \n",
    "init = tf.constant_initializer(value=weights,dtype=tf.float32) \n",
    "var = tf.get_variable(name=\"up_filter\", initializer=init,shape=weights.shape) # 4,4,1000,1000\n",
    "deconv = tf.nn.conv2d_transpose(bottom, var, output_shape, strides=strides, padding='SAME')\n",
    "#tf.nn.conv2d_transpose(value,filter,output_shape, strides, padding='SAME',data_format='NHWC',name=None)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    a=sess.run(deconv, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
    "a=tf.shape(t)  # [2, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=tf.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=np.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.placeholder(\"float\")\n",
    "feed_dict = {images: img1}\n",
    "batch_images = tf.expand_dims(images, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb800891be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight=tf.constant([[[[1.]],[[1.]]],\n",
    "                    [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d=tf.nn.conv2d(image,weight,strides=[1,1,1,1],padding='VALID')\n",
    "#hmm why does it set strides to 1 1 1 1 ??? what does it mean?\n",
    "conv2d_img=conv2d.eval()\n",
    "weight2=tf.constant([[[[0.0625]],[[0.1875]],[[0.1875]],[[0.0625]]],\n",
    "                    [[[0.1875]],[[0.5625]],[[0.5625]],[[0.1875]]],\n",
    "                    [[[0.1875]],[[0.5625]],[[0.5625]],[[0.0625]]],\n",
    "                    [[[0.0625]],[[0.1875]],[[0.1875]],[[0.0625]]]])\n",
    "#weight2=tf.constant([[[[1.0]],[[1.0]],[[1.0]],[[1.0]]],\n",
    "#                    [[[1.0]],[[1.0]],[[1.0]],[[1.0]]],\n",
    "#                    [[[1.0]],[[1.0]],[[1.0]],[[1.0]]],\n",
    "#                    [[[1.0]],[[1.0]],[[1.0]],[[1.0]]]])\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "k=5\n",
    "s=2\n",
    "deconv2d=tf.nn.conv2d_transpose(image,weight2,[1,k,k,1],strides=[1,s,s,1],padding='SAME')\n",
    "#deconv3d=tf.nn.conv2d_transpose(conv2d,weight2,[1,k,k,1],strides=[1,s,s,1],padding='SAME')\n",
    "\n",
    "#this is show what is result.\n",
    "conv2d_img = np.swapaxes(image, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5625 0.9375 1.3125 1.6875 2.0625]\n",
      " [1.3125 2.     2.375  3.     3.25  ]\n",
      " [2.4375 3.5    4.     4.5    5.    ]\n",
      " [3.5625 5.     5.     6.     5.875 ]\n",
      " [4.6875 6.5    7.     7.5    8.    ]]\n",
      "[[0.5625 0.9375 1.3125 1.6875 2.0625]\n",
      " [1.3125 2.     2.375  3.     3.25  ]\n",
      " [2.4375 3.5    4.     4.5    5.    ]\n",
      " [3.5625 5.     5.     6.     5.875 ]\n",
      " [4.6875 6.5    7.     7.5    8.    ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=deconv2d.eval()\n",
    "print(a.reshape([k,k]))\n",
    "conv2d_img = np.swapaxes(a, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(k,k))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(k,k), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in range(width):\n",
    "            for y in range(height):\n",
    "                value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
    "                bilinear[x, y] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=4; height=4;      f = ceil(width/2.0);        c = (2 * f - 1 - f % 2) / (2.0 * f); bilinear = np.zeros([width, height])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 12. 12.  0. 16. 16. 16.]\n",
      " [12. 24. 12.  0. 16. 32. 16.]\n",
      " [12. 12. 12.  0. 16. 16. 16.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [24. 24. 24.  0. 28. 28. 28.]\n",
      " [24. 48. 24.  0. 28. 56. 28.]\n",
      " [24. 24. 24.  0. 28. 28. 28.]]\n"
     ]
    }
   ],
   "source": [
    "w=tf.constant(np.ones([3,3]).reshape(3,3,1,1))\n",
    "weight3=tf.constant([[[[1.0]],[[1.0]],[[1.0]]],\n",
    "                    [[[1.0]],[[2.0]],[[1.0]]],\n",
    "                    [[[1.0]],[[1.0]],[[1.0]]]])\n",
    "k=7\n",
    "s=4\n",
    "deconv2d=tf.nn.conv2d_transpose(conv2d_img,weight3,[1,k,k,1],strides=[1,s,s,1],padding='SAME')\n",
    "a=deconv2d.eval()\n",
    "print(a.reshape([k,k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12., 16.],\n",
       "       [24., 28.]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_img.reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(4), Dimension(1), Dimension(1)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_100:0' shape=(4, 4) dtype=float64>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=tf.expand_dims(bilinear,2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=tf.expand_dims(b,0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.0625],\n",
       "         [0.1875],\n",
       "         [0.1875],\n",
       "         [0.0625]],\n",
       "\n",
       "        [[0.1875],\n",
       "         [0.5625],\n",
       "         [0.5625],\n",
       "         [0.1875]],\n",
       "\n",
       "        [[0.1875],\n",
       "         [0.5625],\n",
       "         [0.5625],\n",
       "         [0.1875]],\n",
       "\n",
       "        [[0.0625],\n",
       "         [0.1875],\n",
       "         [0.1875],\n",
       "         [0.0625]]]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'shaep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-0c3e256ed9da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshaep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'shaep'"
     ]
    }
   ],
   "source": [
    "b.shaep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(4), Dimension(4), Dimension(1)])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1-1_pyth3",
   "language": "python",
   "name": "tensorflow1-1_pyth3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
